Manual HANA HA on Kubernetes with a Single StatefulSet

Part 1: Kubernetes Resource Setup
We will create a Secret, a headless Service, and a StatefulSet with replicas: 2.

Secret: Contains the master password in the required password.json format. The data is base64 encoded.
Service: A headless service that provides stable DNS names for our pods (hana-cluster-0 and hana-cluster-1).
StatefulSet: Manages the two pods, ensuring they have stable identities and their own persistent storage.

➤ kubectl apply -f hana-clsuter-sts.yaml
secret/hana-cluster-auth created
service/hana-pods created
statefulset.apps/hana-cluster created





. Monitor Pod Startup
Wait for both pods, hana-cluster-0 and hana-cluster-1, to be in the Running state. This will take 5-15 minutes as each pod runs the internal HANA installation process using the password you provided.

kubectl get pods -n hana-demo -w



You can check the logs to see the progress. You are waiting for the Startup finished! message in the logs of both pods.
Generated bash
kubectl logs -f hana-cluster-0 -n hana-demo
kubectl logs -f hana-cluster-1 -n hana-demo






Step 2: Manually Configure System Replication
At this point, you have two identical, independent HANA instances running. Now, we will configure them to replicate.


1. Create a Backup and Enable Replication on the Primary (hana-cluster-0)

HANA requires an initial backup before replication can be enabled.



➤ kubectl exec -it -n demo hana-cluster-0 -- bash

hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> HDB info
USER          PID     PPID  %CPU        VSZ        RSS COMMAND
hxeadm       2188        0   0.0       7212       4352 bash
hxeadm       2253     2188   0.0       6432       3584  \_ /bin/sh /usr/sap/HXE/HDB90/HDB info
hxeadm       2286     2253  66.6      23900       3840      \_ ps fx -U hxeadm -o user:8,pid:8
hxeadm          1        0   0.0       2540       1536 sleep 5184000
hxeadm          7        1   0.0       7344       4096 /bin/bash /run_hana --agree-to-sap-lice
hxeadm        956        1   0.0     359568      52380 hdbdaemon
hxeadm        962      956  36.8    5492180    2588436  \_ hdbnameserver
hxeadm       1406      956   0.9     727748     191856  \_ hdbcompileserver
hxeadm       1407      956   0.9     956320     208668  \_ hdbpreprocessor
hxeadm       1443      956   1.1    1170984     353644  \_ hdbdiserver
hxeadm       1444      956   1.4    1543804     447132  \_ hdbwebdispatcher
hxeadm       1558      956  47.0    5117796    3472240  \_ hdbindexserver -port 39040
hxeadm       1027        1   0.0     466828      38584 hdbrsutil  --start --port 39001 --volum
hxeadm       1606        1   0.0     466900      38656 hdbrsutil  --start --port 39040 --volum

hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> hdbsql -i 90 -d SYSTEMDB -u SYSTEM -p "HanaCluster123!"

Welcome to the SAP HANA Database interactive terminal.
                                           
Type:  \h for help with commands          
       \q to quit                         

hdbsql SYSTEMDB=> 

hdbsql SYSTEMDB=> BACKUP DATA USING FILE ('/hana/mounts/backup/data_backup')
0 rows affected (overall time 2790.165 msec; server time 2789.981 msec)

hdbsql SYSTEMDB=> q
hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90>
hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> hdbnsutil -sr_enable --name=SITE_A
nameserver is active, proceeding ...
successfully enabled system as system replication source site
done.
hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> 


hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
there are no secondary sites attached

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: PRIMARY
site id: 1
site name: SITE_A
hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> 








2. Register the Secondary (hana-cluster-1)

➤ kubectl exec -it -n demo hana-cluster-1 -- bash
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90>




# Now, register with the primary, using its stable DNS name
# The name is <pod-name>.<service-name>.<namespace>.svc.cluster.local

hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> hdbnsutil -sr_register   --name=SITE_B   --remoteHost=hana-cluster-0.hana-pods.demo.svc.cluster.local   --remoteInstance=90   --replicationMode=sync --online

--operationMode not set; using default from global.ini/[system_replication]/operation_mode: logreplay
adding site ...
collecting information ...
unable to contact primary site; to hana-cluster-0.hana-pods.demo.svc.cluster.local:49006; original error: ssl: bad certificate (Internal Error Details: exception  1: no.300015  (Crypto/Shared/SSL/CommonCrypto/Engine.cpp:487) TID: 2324
    SSL certificate validation failed: SSL error [536872221]: Unknown error, General error: 0x2000051d | SAPCRYPTOLIB | SSL_connect
SSL API error
Failed to verify peer certificate. Peer not trusted.
0xa0600203 | SSL_ | ssl3_connect
Peer not trusted
0xa0600203 | SSL_ | ssl3_get_server_certificate
Peer not trusted
0xa0600203 | SSL_ | ssl3_decode_server_certificate
Peer not trusted
0xa0600203 | SSL_ | ssl_verify_peer_certificates
Peer not trusted
0xa0600203 | SSL_ | ssl_cert_checker_verify_certificates
Peer not trusted
Certificate verification failed
0xa0600203 | SSL_ | ssl_cert_checker_verify_certificates
Peer not trusted
----- BEGIN VERIFICATION RESULT -----
 # --- Messages -----------
 ERROR: Signature error. Issuer Cert: [00:51:2F:84] CN=DBaaS HXE, OU=HANA, O=SAP SE, L=Berlin, SP=Berlin, C=DE. Cert: [52:A2:1B:A0] CN=hana-cluster-0_HXE_90, O=SAP System PKI, C=DE.
 # --- Summary ---,location=hana-cluster-0.hana-pods.demo.svc.cluster.local:49006. Are system PKI SSFS data and key files copied from the primary system to the secondary system? (Please refer to SAP Note 2369981); 
failed. trace file nameserver_hana-cluster-1.00000.000.trc may contain more error details.





neaj@neaj-pc:~/g/s/g/N/y/hana|main⚡*?
kubectl cp demo/hana-cluster-0:/usr/sap/HXE/SYS/global/security/rsecssfs/data/SSFS_HXE.DAT ./SSFS_HXE.DAT

tar: Removing leading `/' from member names
neaj@neaj-pc:~/g/s/g/N/y/hana|main⚡*?
kubectl cp demo/hana-cluster-0:/usr/sap/HXE/SYS/global/security/rsecssfs/key/SSFS_HXE.KEY ./SSFS_HXE.KEY

tar: Removing leading `/' from member names
neaj@neaj-pc:~/g/s/g/N/y/hana|main⚡*?
kubectl cp ./SSFS_HXE.DAT demo/hana-cluster-1:/usr/sap/HXE/SYS/global/security/rsecssfs/data/SSFS_HXE.DAT

neaj@neaj-pc:~/g/s/g/N/y/hana|main⚡*?
kubectl cp ./SSFS_HXE.KEY demo/hana-cluster-1:/usr/sap/HXE/SYS/global/security/rsecssfs/key/SSFS_HXE.KEY

neaj@neaj-pc:~/g/s/g/N/y/hana|main⚡*?
➤ kubectl delete pod -n demo hana-cluster-1 
pod "hana-cluster-1" deleted


hxeadm@hana-cluster-1:/usr/sap/HXE/SYS/global/security/rsecssfs/key> hdbnsutil -sr_register \
>   --name=SITE_B \
>   --remoteHost=hana-cluster-0 \
>   --remoteInstance=90 \
>   --replicationMode=sync \
>   --online
--operationMode not set; using default from global.ini/[system_replication]/operation_mode: logreplay
adding site ...
collecting information ...
unable to contact primary site host hana-cluster-0:49006. Internal Error Details: exception  1: no.2112401  (Basis/HanaNet/LSL/impl/GAIResolver.cpp:560) TID: 1449
    Failed to resolve hostname [hana-cluster-0] with exception
exception throw location:
   0: 0x000073a2951c9b36 in TRexUtils::Deserializer::readBool()+0x2f77 (libhdbnetrpc.so)
   1: 0x000073a294ff1ea2 in comm::resolve_name(char const*, char*, unsigned long)+0x131 (libhdbnetrpc.so)
   2: 0x000073a29508c6bd in TrexNet::Configuration::getHostAddress(char const*, char*, unsigned long)+0x1ec (libhdbnetrpc.so)
   3: 0x000073a2950ad501 in TrexNet::Requestor::getEndPoint(char const*, unsigned short, char)+0x70 (libhdbnetrpc.so)
   4: 0x000073a2950af906 in TrexNet::Requestor::getChannel(char const*, unsigned short, TrexNet::RequestParameters const&)+0x85 (libhdbnetrpc.so)
   5: 0x000073a2951204f9 in ltt::operator<<(ltt::basic_ostream<char, ltt::char_traits<char> >&, std::source_location const&)+0x9c78 (libhdbnetrpc.so)
   6: 0x000073a29509a4f5 in TrexNet::Request::Request(ltt::basic_string_view<char, ltt::char_traits<char> >, Basis::HostAndPort const&, TrexNet::RequestParameters const&)+0x14 (libhdbnetrpc.so)
   7: 0x000073a29881a3dd in NameServer::TNSClientCacheActiveServersRefresher::~TNSClientCacheActiveServersRefresher()+0x28ec (libhdbbasement.so)
   8: 0x000073a2987e8cb3 in NameServer::TNSClientBase<NameServer::TNSClientErrorGuard<false> >::sendRequestTo(NameServer::Request const&, NameServer::Response&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, unsigned short, NameServer::TrexNetRequestHolder*, bool, char)+0x122 (libhdbbasement.so)
   9: 0x000073a2986f3b3d in NameServer::DRClientBase<NameServer::TNSClientErrorGuard<false> >::drSendRequestTo(NameServer::Request&, NameServer::Response&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, unsigned short, unsigned short&, NameServer::TrexNetRequestHolder*, bool, bool)+0xcc (libhdbbasement.so)
  10: 0x000073a29870739f in NameServer::DRClientBase<NameServer::TNSClientErrorGuard<false> >::drRegisterDatacenter(NameServer::RegistrationInputParameters&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, bool const&, bool, bool, bool, bool, bool)+0x141e (libhdbbasement.so)
  11: 0x000062ac014827d5 in ltt::exception_ptr::get_exception_ptr() const+0x46204 (hdbnsutil)
  12: 0x000062ac0142b426 in __gmon_start__+0x38425 (hdbnsutil)
  13: 0x000073a294126fae in mainInitialPhase+0xded (libhdbbasis.so)
  14: 0x000073a292fdb1fd in __libc_start_main+0xee (libc.so.6)
  15: 0x000062ac0142e959 in _start+0x28 (hdbnsutil)

exception type information:
 - 0: public HanaNet::RuntimeError@0x000073a294713f70 SI
   - 0: public ltt::exception@0x000073a293618238
exception  2: no.2050100  (Basis/System/SystemCall.hpp:377) TID: 1449
    System call failed [addrinfo:-2]: Name or service not known
exception throw location:
   0: 0x000073a2941471ac in System::SystemCallException::SystemCallException(char const*, int, ltt::error_code const&)+0x3b (libhdbbasis.so)
   1: 0x000073a2951d5ca2 in TRexUtils::Deserializer::readBool()+0xf0e3 (libhdbnetrpc.so)
   2: 0x000073a2951d342f in TRexUtils::Deserializer::readBool()+0xc870 (libhdbnetrpc.so)
   3: 0x000073a2950d7b3c in HanaNet::LSL::Socket::Socket(ltt::allocator&)+0x1db (libhdbnetrpc.so)
   4: 0x000073a2950d7bb8 in HanaNet::LSL::Impl::GAIResolver::makeDNSEntry(HanaNet::LSL::HostNameView)+0x57 (libhdbnetrpc.so)
   5: 0x000073a2950da868 in HanaNet::LSL::Impl::GAIResolver::resolveImpl(HanaNet::LSL::HostNameView)+0x327 (libhdbnetrpc.so)
   6: 0x000073a294ff1ea2 in comm::resolve_name(char const*, char*, unsigned long)+0x131 (libhdbnetrpc.so)
   7: 0x000073a29508c6bd in TrexNet::Configuration::getHostAddress(char const*, char*, unsigned long)+0x1ec (libhdbnetrpc.so)
   8: 0x000073a2950ad501 in TrexNet::Requestor::getEndPoint(char const*, unsigned short, char)+0x70 (libhdbnetrpc.so)
   9: 0x000073a2950af906 in TrexNet::Requestor::,location=hana-cluster-0:49006. Trying old-style port (port offset +100)...hana-cluster-0:49006
unable to contact primary site; to hana-cluster-0:39106; original error: Internal Error Details: exception  1: no.2112401  (Basis/HanaNet/LSL/impl/GAIResolver.cpp:560) TID: 1449
    Failed to resolve hostname [hana-cluster-0] with exception
exception throw location:
   0: 0x000073a2951c9b36 in TRexUtils::Deserializer::readBool()+0x2f77 (libhdbnetrpc.so)
   1: 0x000073a294ff1ea2 in comm::resolve_name(char const*, char*, unsigned long)+0x131 (libhdbnetrpc.so)
   2: 0x000073a29508c6bd in TrexNet::Configuration::getHostAddress(char const*, char*, unsigned long)+0x1ec (libhdbnetrpc.so)
   3: 0x000073a2950ad501 in TrexNet::Requestor::getEndPoint(char const*, unsigned short, char)+0x70 (libhdbnetrpc.so)
   4: 0x000073a2950af906 in TrexNet::Requestor::getChannel(char const*, unsigned short, TrexNet::RequestParameters const&)+0x85 (libhdbnetrpc.so)
   5: 0x000073a2951204f9 in ltt::operator<<(ltt::basic_ostream<char, ltt::char_traits<char> >&, std::source_location const&)+0x9c78 (libhdbnetrpc.so)
   6: 0x000073a29509a4f5 in TrexNet::Request::Request(ltt::basic_string_view<char, ltt::char_traits<char> >, Basis::HostAndPort const&, TrexNet::RequestParameters const&)+0x14 (libhdbnetrpc.so)
   7: 0x000073a29881a3dd in NameServer::TNSClientCacheActiveServersRefresher::~TNSClientCacheActiveServersRefresher()+0x28ec (libhdbbasement.so)
   8: 0x000073a2987e8cb3 in NameServer::TNSClientBase<NameServer::TNSClientErrorGuard<false> >::sendRequestTo(NameServer::Request const&, NameServer::Response&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, unsigned short, NameServer::TrexNetRequestHolder*, bool, char)+0x122 (libhdbbasement.so)
   9: 0x000073a2986f3b3d in NameServer::DRClientBase<NameServer::TNSClientErrorGuard<false> >::drSendRequestTo(NameServer::Request&, NameServer::Response&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, unsigned short, unsigned short&, NameServer::TrexNetRequestHolder*, bool, bool)+0xcc (libhdbbasement.so)
  10: 0x000073a2987087c0 in NameServer::DRClientBase<NameServer::TNSClientErrorGuard<false> >::drRegisterDatacenter(NameServer::RegistrationInputParameters&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, ltt_adp::basic_string<char, ltt::char_traits<char>, ltt::integral_constant<bool, true> > const&, bool const&, bool, bool, bool, bool, bool)+0x283f (libhdbbasement.so)
  11: 0x000062ac014827d5 in ltt::exception_ptr::get_exception_ptr() const+0x46204 (hdbnsutil)
  12: 0x000062ac0142b426 in __gmon_start__+0x38425 (hdbnsutil)
  13: 0x000073a294126fae in mainInitialPhase+0xded (libhdbbasis.so)
  14: 0x000073a292fdb1fd in __libc_start_main+0xee (libc.so.6)
  15: 0x000062ac0142e959 in _start+0x28 (hdbnsutil)

exception type information:
 - 0: public HanaNet::RuntimeError@0x000073a294713f70 SI
   - 0: public ltt::exception@0x000073a293618238
exception  2: no.2050100  (Basis/System/SystemCall.hpp:377) TID: 1449
    System call failed [addrinfo:-2]: Name or service not known
exception throw location:
   0: 0x000073a2941471ac in System::SystemCallException::SystemCallException(char const*, int, ltt::error_code const&)+0x3b (libhdbbasis.so)
   1: 0x000073a2951d5ca2 in TRexUtils::Deserializer::readBool()+0xf0e3 (libhdbnetrpc.so)
   2: 0x000073a2951d342f in TRexUtils::Deserializer::readBool()+0xc870 (libhdbnetrpc.so)
   3: 0x000073a2950d7b3c in HanaNet::LSL::Socket::Socket(ltt::allocator&)+0x1db (libhdbnetrpc.so)
   4: 0x000073a2950d7bb8 in HanaNet::LSL::Impl::GAIResolver::makeDNSEntry(HanaNet::LSL::HostNameView)+0x57 (libhdbnetrpc.so)
   5: 0x000073a2950da868 in HanaNet::LSL::Impl::GAIResolver::resolveImpl(HanaNet::LSL::HostNameView)+0x327 (libhdbnetrpc.so)
   6: 0x000073a294ff1ea2 in comm::resolve_name(char const*, char*, unsigned long)+0x131 (libhdbnetrpc.so)
   7: 0x000073a29508c6bd in TrexNet::Configuration::getHostAddress(char const*, char*, unsigned long)+0x1ec (libhdbnetrpc.so)
   8: 0x000073a2950ad501 in TrexNet::Requestor::getEndPoint(char const*, unsigned short, char)+0x70 (libhdbnetrpc.so)
   9: 0x000073a2950af906 in TrexNet::Requestor::,location=hana-cluster-0:39106; 
failed. trace file nameserver_hana-cluster-1.00000.000.trc may contain more error details.
hxeadm@hana-cluster-1:/usr/sap/HXE/SYS/global/security/rsecssfs/key> 






  kubectl exec -it -n demo hana-cluster-1 -- bash
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90>  hdbnsutil -sr_register   --name=SITE_B   --remoteHost=hana-cluster-0   --remoteInstance=90   --replicationMode=sync --online

--operationMode not set; using default from global.ini/[system_replication]/operation_mode: logreplay
adding site ...
collecting information ...
INFO: no copy check for systemPKI SSFS files as primary does not support this (older version than secondary) or primary has deactivated it explicitly
remoteHost does not match with any host of the source site. all hosts of source and target site must be able to resolve all hostnames of both sites correctly; 
failed. trace file nameserver_hana-cluster-1.00000.000.trc may contain more error details.
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> 
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> 








hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> hdbnsutil -sr_register \
>   --name=SITE_B \
>   --remoteHost=hana-cluster-0.hana-pods.demo.svc.cluster.local \
>   --remoteInstance=90 \
>   --replicationMode=sync \
>   --online
--operationMode not set; using default from global.ini/[system_replication]/operation_mode: logreplay
adding site ...
collecting information ...
INFO: no copy check for systemPKI SSFS files as primary does not support this (older version than secondary) or primary has deactivated it explicitly
remoteHost does not match with any host of the source site. all hosts of source and target site must be able to resolve all hostnames of both sites correctly; 
failed. trace file nameserver_hana-cluster-1.00000.000.trc may contain more error details.

















You have hit on the absolute core of the problem, and your thinking is exactly right.
Yes, to solve the "Permission denied" error when writing to /etc/hosts, you must ensure that part of the script runs as the root user.
However, you do not need to modify the HANA image itself. The beauty of Kubernetes is that you can control the execution context from your YAML manifest.
Let's break down why this is happening and the correct way to fix it in your StatefulSet definition.
The Problem: User Context in the saplabs/hanaexpress Image
Default User: The saplabs/hanaexpress Docker image is designed for security and best practices. Its Dockerfile likely contains a USER hxeadm instruction. This means that when you run the container, the main process (/run_hana) starts as the non-privileged hxeadm user by default.
Kubernetes Command: When you specify a command in your Kubernetes pod spec, that command is executed by the container's default user. In this case, your entire startup script is being executed as hxeadm.
The Permission Error: The hxeadm user does not have permission to write to the /etc/hosts file, which is owned by root. This is standard Linux security.
The Solution: Run the Startup Script as root
We need to tell Kubernetes to run our specific startup logic as the root user before handing off control to the main HANA process. We can do this cleanly within the StatefulSet manifest without building a new image.
The securityContext field in a container spec allows us to override the default user.
A More Advanced (But Correct) Approach: The Init Container
The most "Kubernetes-native" and robust way to handle privileged, one-time setup tasks is with an Init Container.
What is an Init Container? It's a special container that runs to completion before the main application container starts. It's perfect for tasks like setting up permissions, populating configuration, or, in our case, modifying /etc/hosts.
Here is how you would modify your StatefulSet to use this pattern.
Final, Corrected hana-cluster.yaml using an Init Container
Generated yaml
# hana-cluster.yaml
# ... (Secret and Service manifests are fine) ...
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: hana-cluster
  namespace: hana-demo
spec:
  replicas: 2
  serviceName: "hana-pods"
  selector:
    matchLabels:
      app: hana-cluster
  template:
    metadata:
      labels:
        app: hana-cluster
    spec:
      subdomain: "hana-pods"
      # --- Init Container for privileged setup ---
      initContainers:
      - name: configure-hosts
        image: busybox:1.36 # Use a small, simple image for the task
        # This container will run as root by default
        command:
        - /bin/sh
        - -c
        - |
          set -ex
          
          # Determine peer's hostname based on my own hostname
          if [[ "$(hostname)" == "hana-cluster-0" ]]; then
            PEER_HOSTNAME="hana-cluster-1"
          else
            PEER_HOSTNAME="hana-cluster-0"
          fi
          
          NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)
          PEER_FQDN="${PEER_HOSTNAME}.hana-pods.${NAMESPACE}.svc.cluster.local"
          
          # Wait until the peer's FQDN is resolvable
          while ! getent hosts ${PEER_FQDN}; do
            echo "InitContainer: Waiting for peer DNS..."
            sleep 2
          done
          
          # Get the peer's IP and add it to a temporary file
          PEER_IP=$(getent hosts ${PEER_FQDN} | awk '{print $1}')
          echo "${PEER_IP} ${PEER_HOSTNAME}" > /hosts-share/peer_entry
          
          echo "InitContainer: Host entry prepared."
        volumeMounts:
        # Mount a shared volume to pass the hosts entry to the main container
        - name: hosts-share
          mountPath: /hosts-share

      # --- Main Application Container ---
      containers:
      - name: hana
        image: saplabs/hanaexpress:latest
        command:
        - /bin/bash
        - -c
        - |
          # This part of the script runs as root before run_hana drops privileges
          set -ex
          
          # Append the peer entry prepared by the init container to /etc/hosts
          cat /hosts-share/peer_entry >> /etc/hosts
          echo "Appended peer to /etc/hosts:"
          cat /etc/hosts

          # Now, hand off to the main entrypoint
          exec /run_hana --agree-to-sap-license --passwords-url file:///etc/hana-secrets/password.json
        securityContext:
          privileged: true
        volumeMounts:
        - name: hana-data
          mountPath: /hana/mounts
        - name: password-secret
          mountPath: /etc/hana-secrets
          readOnly: true
        # Mount the shared volume to read the hosts entry
        - name: hosts-share
          mountPath: /hosts-share
      
      volumes:
      - name: password-secret
        secret:
          secretName: hana-cluster-auth
      # Define the shared volume
      - name: hosts-share
        emptyDir: {} # A simple, temporary volume shared between init and main containers
  
  volumeClaimTemplates:
  - metadata:
      name: hana-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: your-fast-storageclass # <-- IMPORTANT: Change this
      resources:
        requests:
          storage: "100Gi"
￼content_copy
￼download
Use code with caution.
Yaml
Why the Init Container Approach is Better
Separation of Concerns: The privileged task (network discovery and host file preparation) is done in a minimal, separate busybox container. The main hana container's startup logic is simpler.
Clarity: It makes the startup sequence explicit. Kubernetes guarantees that the initContainers will run to completion before the main containers are started.
Security: While the main hana container still needs privileged: true, you are isolating the host file modification logic. The main container's script is now much simpler.
How it Works:
An emptyDir volume named hosts-share is created for the pod.
The configure-hosts init container runs as root, does the DNS lookup, and writes the single line (10.x.x.x hana-cluster-0) into a file on this shared volume.
The init container exits.
The main hana container starts. Its startup script (also running as root initially) simply appends the content from the shared file into /etc/hosts and then execs the run_hana process.
This pattern correctly solves the permissions issue in a clean, declarative, and Kubernetes-native way.










hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> hdbnsutil -sr_register   --name=SITE_B   --remoteHost=hana-cluster-0   --remoteInstance=90   --replicationMode=sync --online
--operationMode not set; using default from global.ini/[system_replication]/operation_mode: logreplay
adding site ...
collecting information ...
updating local ini files ...
done.
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> 



hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
this system is either not running or not primary system replication site

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: SYNC
site id: 2
site name: SITE_B
active primary site: 1
primary masters: hana-cluster-0
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> 








Part 1: Verifying the System Replication Cluster

Step 1: Check the Status on the Primary (hana-cluster-0)


hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
|Database |Host           |Port  |Service Name |Volume ID |Site ID |Site Name |Secondary      |Secondary |Secondary |Secondary |Secondary     |Replication |Replication |Replication                                                                   |Secondary    |
|         |               |      |             |          |        |          |Host           |Port      |Site ID   |Site Name |Active Status |Mode        |Status      |Status Details                                                                |Fully Synced |
|-------- |-------------- |----- |------------ |--------- |------- |--------- |-------------- |--------- |--------- |--------- |------------- |----------- |----------- |----------------------------------------------------------------------------- |------------ |
|SYSTEMDB |hana-cluster-0 |39001 |nameserver   |        1 |      1 |SITE_A    |hana-cluster-1 |    39001 |        2 |SITE_B    |YES           |SYNC        |ACTIVE      |                                                                              |        True |
|HXE      |hana-cluster-0 |39040 |indexserver  |        2 |      1 |SITE_A    |hana-cluster-1 |    39040 |        2 |SITE_B    |STARTING      |SYNC        |ERROR       |Connection refused: Primary needs initial data backup for system replication! |       False |

status system replication site "2": ERROR
overall system replication status: ERROR

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: PRIMARY
site id: 1
site name: SITE_A
hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> hdbsql -i 90 -d HXE -u SYSTEM -p "HanaCluster123!"

Welcome to the SAP HANA Database interactive terminal.
                                           
Type:  \h for help with commands          
       \q to quit                         

hdbsql HXE=> BACKUP DATA USING FILE ('/hana/mounts/backup/data_backup');
0 rows affected (overall time 22.954223 sec; server time 22.954029 sec)

hdbsql HXE=> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
* 257: sql syntax error: incorrect syntax near "python": line 1 col 1 (at pos 1) SQLSTATE: HY000
hdbsql HXE=> q
hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
|Database |Host           |Port  |Service Name |Volume ID |Site ID |Site Name |Secondary      |Secondary |Secondary |Secondary |Secondary     |Replication |Replication |Replication    |Secondary    |
|         |               |      |             |          |        |          |Host           |Port      |Site ID   |Site Name |Active Status |Mode        |Status      |Status Details |Fully Synced |
|-------- |-------------- |----- |------------ |--------- |------- |--------- |-------------- |--------- |--------- |--------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |hana-cluster-0 |39001 |nameserver   |        1 |      1 |SITE_A    |hana-cluster-1 |    39001 |        2 |SITE_B    |YES           |SYNC        |ACTIVE      |               |        True |
|HXE      |hana-cluster-0 |39040 |indexserver  |        2 |      1 |SITE_A    |hana-cluster-1 |    39040 |        2 |SITE_B    |YES           |SYNC        |ACTIVE      |               |        True |

status system replication site "2": ACTIVE
overall system replication status: ACTIVE

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: PRIMARY
site id: 1
site name: SITE_A
hxeadm@hana-cluster-0:/usr/sap/HXE/HDB90> 




Check with SQL (Optional but good to know):




hxeadm@hana-cluster-0:/hana/mounts/backup> hdbsql -i 90 -d SYSTEMDB -u SYSTEM -p "HanaCluster123!" 

Welcome to the SAP HANA Database interactive terminal.
                                           
Type:  \h for help with commands          
       \q to quit                         

hdbsql SYSTEMDB=> SELECT * FROM "SYS_DATABASES"."M_SERVICE_REPLICATION";
DATABASE_NAME,HOST,PORT,VOLUME_ID,SITE_ID,SITE_NAME,SECONDARY_HOST,SECONDARY_PORT,SECONDARY_SITE_ID,SECONDARY_SITE_NAME,SECONDARY_ACTIVE_STATUS,SECONDARY_CON
NECT_TIME,SECONDARY_RECONNECT_COUNT,SECONDARY_FAILOVER_COUNT,SECONDARY_FULLY_RECOVERABLE,REPLICATION_MODE,REPLICATION_STATUS,REPLICATION_STATUS_DETAILS,FULL_
SYNC,LAST_LOG_POSITION,LAST_LOG_POSITION_TIME,LAST_SAVEPOINT_VERSION,LAST_SAVEPOINT_LOG_POSITION,LAST_SAVEPOINT_START_TIME,SHIPPED_LOG_POSITION,SHIPPED_LOG_P
OSITION_TIME,SHIPPED_LOG_BUFFERS_COUNT,SHIPPED_LOG_BUFFERS_SIZE,SHIPPED_LOG_BUFFERS_DURATION,REPLAYED_LOG_POSITION,REPLAYED_LOG_POSITION_TIME,SHIPPED_SAVEPOI
NT_VERSION,SHIPPED_SAVEPOINT_LOG_POSITION,SHIPPED_SAVEPOINT_START_TIME,SHIPPED_FULL_REPLICA_COUNT,SHIPPED_FULL_REPLICA_SIZE,SHIPPED_FULL_REPLICA_DURATION,SHI
PPED_LAST_FULL_REPLICA_SIZE,SHIPPED_LAST_FULL_REPLICA_START_TIME,SHIPPED_LAST_FULL_REPLICA_END_TIME,SHIPPED_DELTA_REPLICA_COUNT,SHIPPED_DELTA_REPLICA_SIZE,SH
IPPED_DELTA_REPLICA_DURATION,SHIPPED_LAST_DELTA_REPLICA_SIZE,SHIPPED_LAST_DELTA_REPLICA_START_TIME,SHIPPED_LAST_DELTA_REPLICA_END_TIME,ASYNC_BUFFER_TOTAL_SIZ
E,ASYNC_BUFFER_USED_SIZE,ASYNC_BUFFER_MAX_USED_SIZE,ASYNC_BUFFER_FULL_COUNT,BACKLOG_SIZE,MAX_BACKLOG_SIZE,BACKLOG_TIME,MAX_BACKLOG_TIME,REPLAY_BACKLOG_SIZE,M
AX_REPLAY_BACKLOG_SIZE,REPLAY_BACKLOG_TIME,MAX_REPLAY_BACKLOG_TIME
"SYSTEMDB","hana-cluster-0",39001,1,1,"SITE_A","hana-cluster-1",39001,2,"SITE_B","YES","2025-07-29 11:52:35.517455000",0,0,"TRUE","SYNC","ACTIVE","","DISABLE
D",4251648,"2025-07-29 12:09:30.985859000",45,4249730,"2025-07-29 12:07:50.987251000",4251648,"2025-07-29 12:09:30.985859000",301,1417216,13490121,4251648,"2
025-07-29 12:09:30.985859000",36,4229634,"2025-07-29 11:52:36.110612000",1,151031808,2381847,151031808,"2025-07-29 11:52:36.110612000","2025-07-29 11:52:38.4
92459000",0,0,0,0,?,?,0,0,0,0,0,0,0,0,0,36864,0,20962634
"HXE","hana-cluster-0",39040,2,1,"SITE_A","hana-cluster-1",39040,2,"SITE_B","YES","2025-07-29 12:04:12.722607000",0,0,"TRUE","SYNC","ACTIVE","","DISABLED",36
30784,"2025-07-29 12:09:21.119411000",34,3612226,"2025-07-29 12:04:36.488798000",3630784,"2025-07-29 12:09:21.119411000",277,1220608,1066179,3630784,"2025-07
-29 12:09:21.119411000",30,3611778,"2025-07-29 12:04:13.223556000",1,167813120,2410915,167813120,"2025-07-29 12:04:13.223556000","2025-07-29 12:04:15.6344710
00",0,0,0,0,?,?,0,0,0,0,0,0,0,0,0,139264,0,20002584
2 rows selected (overall time 14.822 msec; server time 8043 usec)

hdbsql SYSTEMDB=> 




Step 2: Check the Status on the Secondary (hana-cluster-1)



hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> HDB info
USER          PID     PPID  %CPU        VSZ        RSS COMMAND
hxeadm       2345        0   0.0       7212       4096 bash
hxeadm       2824     2345   0.0       6432       3584  \_ /bin/sh /usr/sap/HXE/HDB90/HDB info
hxeadm       2857     2824  66.6      23900       3840      \_ ps fx -U hxeadm -o user:8,pid:8
hxeadm          1        0   0.0       2540       1280 sleep 5184000
hxeadm         14        1   0.0       7344       4096 /bin/bash /run_hana --agree-to-sap-lice
hxeadm        953        1   0.0     356500      53660 hdbdaemon
hxeadm       2438      953   1.9    3176244    1520480  \_ hdbnameserver
hxeadm       2506      953   0.7     827640     204848  \_ hdbcompileserver
hxeadm       2507      953   0.8     954652     219180  \_ hdbpreprocessor
hxeadm       2542      953   2.2    3707552    1613432  \_ hdbindexserver -port 39040
hxeadm       2684      953   0.8    1171444     339712  \_ hdbdiserver
hxeadm       2685      953   1.1    1478272     426564  \_ hdbwebdispatcher
hxeadm       1026        1   0.0          0          0 [hdbrsutil] <defunct>
hxeadm       1576        1   0.0          0          0 [hdbrsutil] <defunct>
hxeadm       2656        1   0.0     466916      38764 hdbrsutil  --start --port 39001 --volum
hxeadm       2809        1   0.0     466996      38828 hdbrsutil  --start --port 39040 --volum
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
this system is either not running or not primary system replication site

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: SYNC
site id: 2
site name: SITE_B
active primary site: 1
primary masters: hana-cluster-0
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> 











Step 3: Test Data Replication (The Ultimate Proof)



Insert data on the Primary:

pod 0:

hdbsql SYSTEMDB=> CREATE TABLE TEST_REPLICATION (ID INT, MSG VARCHAR(50));
0 rows affected (overall time 9013 usec; server time 8855 usec)

hdbsql SYSTEMDB=> INSERT INTO TEST_REPLICATION VALUES (1, 'Replication is working!');
1 row affected (overall time 3047 usec; server time 1878 usec)

hdbsql SYSTEMDB=> SELECT * FROM TEST_REPLICATION;
ID,MSG
1,"Replication is working!"
1 row selected (overall time 7988 usec; server time 262 usec)

hdbsql SYSTEMDB=> q
hxeadm@hana-cluster-0:/hana/mounts/backup> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
|Database |Host           |Port  |Service Name |Volume ID |Site ID |Site Name |Secondary      |Secondary |Secondary |Secondary |Secondary     |Replication |Replication |Replication    |Secondary    |
|         |               |      |             |          |        |          |Host           |Port      |Site ID   |Site Name |Active Status |Mode        |Status      |Status Details |Fully Synced |
|-------- |-------------- |----- |------------ |--------- |------- |--------- |-------------- |--------- |--------- |--------- |------------- |----------- |----------- |-------------- |------------ |
|SYSTEMDB |hana-cluster-0 |39001 |nameserver   |        1 |      1 |SITE_A    |hana-cluster-1 |    39001 |        2 |SITE_B    |YES           |SYNC        |ACTIVE      |               |        True |
|HXE      |hana-cluster-0 |39040 |indexserver  |        2 |      1 |SITE_A    |hana-cluster-1 |    39040 |        2 |SITE_B    |YES           |SYNC        |ACTIVE      |               |        True |

status system replication site "2": ACTIVE
overall system replication status: ACTIVE

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: PRIMARY
site id: 1
site name: SITE_A
hxeadm@hana-cluster-0:/hana/mounts/backup> 






Verify data on the Secondary:
IMPORTANT: A secondary replica in a standard system replication setup cannot be read from directly. Its databases are not active for queries. You would need to configure "Active/Active (Read Enabled)" mode to query it, which is a more advanced topic.
The successful status from systemReplicationStatus.py is your confirmation that the data has been replicated.




hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
this system is either not running or not primary system replication site

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: SYNC
site id: 2
site name: SITE_B
active primary site: 1
primary masters: hana-cluster-0
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> 










CLUSTER SETUP DONE 








Part 2: Testing a Manual Failover (The Takeover)







Step 1: Promote the Secondary (hana-cluster-1)

hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> hdbnsutil -sr_takeover

done.
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> 
hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
there are no secondary sites attached

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: PRIMARY
site id: 2
site name: SITE_B


hxeadm@hana-cluster-1:/usr/sap/HXE/HDB90> hdbsql -i 90 -d SYSTEMDB -u SYSTEM -p "HanaCluster123!"

Welcome to the SAP HANA Database interactive terminal.
                                           
Type:  \h for help with commands          
       \q to quit                         

hdbsql SYSTEMDB=> SELECT * FROM "SYSTEM"."TEST_REPLICATION";
ID,MSG
1,"Replication is working!"
1 row selected (overall time 9936 usec; server time 256 usec)

hdbsql SYSTEMDB=> INSERT INTO TEST_REPLICATION VALUES (2, 'Failover successful!');
1 row affected (overall time 18.155 msec; server time 624 usec)

hdbsql SYSTEMDB=> SELECT * FROM "SYSTEM"."TEST_REPLICATION";
ID,MSG
1,"Replication is working!"
2,"Failover successful!"
2 rows selected (overall time 7323 usec; server time 283 usec)

hdbsql SYSTEMDB=> 






Step 3: What about the Old Primary? (Fencing)
The old primary, hana-cluster-0, is now "fenced". HANA's internal mechanisms will prevent it from starting up as a primary to avoid a "split-brain" scenario where you have two active primaries. If you try to check its status, you'll likely see the services are stopped or in an error state.



hxeadm@hana-cluster-0:/hana/mounts/backup> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
there are no secondary sites attached

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: PRIMARY
site id: 1
site name: SITE_A



hxeadm@hana-cluster-0:/hana/mounts/backup> HDB stop
hdbdaemon will wait maximal 300 seconds for NewDB services finishing.
Stopping instance using: /usr/sap/HXE/SYS/exe/hdb/sapcontrol -prot NI_HTTP -nr 90 -function Stop 400

29.07.2025 12:44:29
Stop
FAIL: NIECONN_REFUSED (Connection refused), NiRawConnect failed in plugin_fopen()





hxeadm@hana-cluster-0:/hana/mounts/backup> hdbnsutil -sr_register \
>   --name=SITE_A \
>   --remoteHost=hana-cluster-1 \
>   --remoteInstance=90 \
>   --replicationMode=sync \
>   --online
--operationMode not set; using default from global.ini/[system_replication]/operation_mode: logreplay
adding site ...
collecting information ...
updating local ini files ...
done.
hxeadm@hana-cluster-0:/hana/mounts/backup> python /usr/sap/HXE/HDB90/exe/python_support/systemReplicationStatus.py
this system is either not running or not primary system replication site

Local System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mode: SYNC
site id: 1
site name: SITE_A
active primary site: 2
primary masters: hana-cluster-1





Now, hana-cluster-0 will start up as a secondary, connect to the new primary (hana-cluster-1), and begin synchronizing any changes that happened while it was offline. You have successfully completed a full manual failover and failback cycle. This is the exact set of commands your Raft-based operator will need to automate.









hxeadm@hana-cluster-0:/hana/mounts> hdbnsutil -sr_state

System Replication State
~~~~~~~~~~~~~~~~~~~~~~~~

online: true

mode: sync
operation mode: logreplay
site id: 1
site name: SITE_A

is source system: false
is secondary/consumer system: true
has secondaries/consumers attached: false
is a takeover active: false
is primary suspended: false
is timetravel enabled: false
replay mode: auto
active primary site: 2

primary masters: hana-cluster-1

Host Mappings:
~~~~~~~~~~~~~~

hana-cluster-0 -> [SITE_B] hana-cluster-1
hana-cluster-0 -> [SITE_A] hana-cluster-0


Site Mappings:
~~~~~~~~~~~~~~
SITE_B (primary/primary)
    |---SITE_A (sync/logreplay)

Tier of SITE_B: 1
Tier of SITE_A: 2

Replication mode of SITE_B: primary
Replication mode of SITE_A: sync

Operation mode of SITE_B: primary
Operation mode of SITE_A: logreplay

Mapping: SITE_B -> SITE_A

Hint based routing site: 
done.